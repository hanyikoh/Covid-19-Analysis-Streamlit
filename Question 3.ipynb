{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import missingno as msno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from boruta import BorutaPy\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "tqdm.pandas(tqdm_notebook)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import r2_score,median_absolute_error,mean_squared_error,mean_absolute_error,accuracy_score\n",
    "from sklearn import preprocessing # label encoding\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split functionn\n",
    "from IPython.display import Image  \n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Path for Dataset & Variable Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(os.getcwd())\n",
    "malaysia_case_dir = path + \"\\dataset\\cases_malaysia.csv\"\n",
    "state_case_dir = path + \"\\dataset\\cases_state.csv\"\n",
    "checkIn_dir = path + \"\\dataset\\covid19-public/mysejahtera/checkin_state.csv\"\n",
    "clusters_dir = path + \"\\dataset\\clusters.csv\"\n",
    "hospital_dir = path + \"\\dataset\\hospital.csv\"\n",
    "pkrc_dir = path + \"\\dataset\\pkrc.csv\"\n",
    "malaysia_tests_dir = path + \"\\dataset\\tests_malaysia.csv\"\n",
    "states_tests_dir = path + \"\\dataset\\tests_state.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Time frame is set from 1/7/2021 until 31/8/2021** \n",
    "</p> This is because the tests_state dataset on MOH only has data available from 1st of July 2021 to 21st of September 2021. Also, the recent data is more helpful to predict future new Covid-19 cases in Malaysia since the data from 2020 to 2021 is having big differences within short time period. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = \"2021-07-01\"\n",
    "end_date = \"2021-08-31\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='FireBrick'>Question 3 (i)</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform EDA by identifying missing value using isna() function, and outliers using box plot, we did not remove outliers because there are important to the datasets and statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis for Malaysia Case Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "malaysia_case_df = pd.read_csv(malaysia_case_dir)\n",
    "after_start_date = malaysia_case_df[\"date\"] >= start_date\n",
    "before_end_date = malaysia_case_df[\"date\"] <= end_date\n",
    "between_two_dates = after_start_date & before_end_date\n",
    "malaysia_case_df = malaysia_case_df.loc[between_two_dates]\n",
    "malaysia_case_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "malaysia_case_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "malaysia_case_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nRow, nCol = malaysia_case_df.shape\n",
    "print(f'There are {nRow} rows and {nCol} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "malaysia_case_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Identify Missing Value\n",
    "</p> Visualize the number of missing values as a bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.bar(malaysia_case_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Identify Outliers\n",
    "</p> Visualize the data using box plot, check the distribution of data and outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 3, figsize=(15, 5), sharey=True)\n",
    "# fig.suptitle('Outliers Visualization')\n",
    "plt.subplots_adjust(left=None, bottom= 0.1, right=None, top=2, wspace=0.2, hspace=0.6)\n",
    "\n",
    "sns.boxplot(data=malaysia_case_df,x=malaysia_case_df[\"cases_new\"],ax=axes[0][0])\n",
    "axes[0][0].set_title('New Case')\n",
    "\n",
    "sns.boxplot(data=malaysia_case_df,x=malaysia_case_df[\"cases_import\"],ax=axes[0][1])\n",
    "axes[0][1].set_title('Case Imprt')\n",
    "\n",
    "sns.boxplot(data=malaysia_case_df,x=malaysia_case_df[\"cases_recovered\"],ax=axes[0][2])\n",
    "axes[0][2].set_title('Case Recovered')\n",
    "\n",
    "sns.boxplot(data=malaysia_case_df,x=malaysia_case_df[\"cluster_import\"],ax=axes[1][0])\n",
    "axes[1][0].set_title('cluster_workplace')\n",
    "\n",
    "sns.boxplot(data=malaysia_case_df,x=malaysia_case_df[\"cluster_religious\"],ax=axes[1][1])\n",
    "axes[1][1].set_title('cluster_religious')\n",
    "\n",
    "sns.boxplot(data=malaysia_case_df,x=malaysia_case_df[\"cluster_community\"],ax=axes[1][2])\n",
    "axes[1][2].set_title('cluster_community')\n",
    "\n",
    "sns.boxplot(data=malaysia_case_df,x=malaysia_case_df[\"cluster_highRisk\"],ax=axes[2][0])\n",
    "axes[2][0].set_title('cluster_highRisk')\n",
    "\n",
    "sns.boxplot(data=malaysia_case_df,x=malaysia_case_df[\"cluster_education\"],ax=axes[2][1])\n",
    "axes[2][1].set_title('cluster_education')\n",
    "\n",
    "sns.boxplot(data=malaysia_case_df,x=malaysia_case_df[\"cluster_detentionCentre\"],ax=axes[2][2])\n",
    "axes[2][2].set_title('cluster_detentionCentre')\n",
    "\n",
    "sns.boxplot(data=malaysia_case_df,x=malaysia_case_df[\"cluster_workplace\"],ax=axes[3][0])\n",
    "axes[3][0].set_title('cluster_workplace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis for State Case Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_case_df = pd.read_csv(state_case_dir)\n",
    "after_start_date = state_case_df[\"date\"] >= start_date\n",
    "before_end_date = state_case_df[\"date\"] <= end_date\n",
    "between_two_dates = after_start_date & before_end_date\n",
    "state_case_df = state_case_df.loc[between_two_dates]\n",
    "state_case_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_case_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_case_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_case_df.groupby([state_case_df['date']]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_case_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Identify Missing Value\n",
    "</p> Visualize the number of missing values as a bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.bar(state_case_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Identify Outliers\n",
    "</p> Visualize the data using box plot, check the distribution of data and outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5), sharey=True)\n",
    "# fig.suptitle('Outliers Visualization')\n",
    "plt.subplots_adjust(left=None, bottom= 0.1, right=None, top=1, wspace=0.2, hspace=0.6)\n",
    "\n",
    "# sns.boxplot(data=state_case_df,x=state_case_df[\"cases_new\"],ax=axes[0][0])\n",
    "# axes[0][0].set_title('Date')\n",
    "# sns.boxplot(data=state_case_df,x=state_case_df[\"cases_new\"],ax=axes[0][1])\n",
    "# axes[0][1].set_title('State')\n",
    "sns.boxplot(data=state_case_df,x=state_case_df[\"cases_import\"],ax=axes[0])\n",
    "axes[0].set_title('Import Case')\n",
    "sns.boxplot(data=state_case_df,x=state_case_df[\"cases_new\"],ax=axes[1])\n",
    "axes[1].set_title('New Case')\n",
    "sns.boxplot(data=state_case_df,x=state_case_df[\"cases_recovered\"],ax=axes[2])\n",
    "axes[2].set_title('Recovered Case')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis for Clusters Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_df = pd.read_csv(clusters_dir)\n",
    "after_start_date = clusters_df[\"date_announced\"] >= start_date\n",
    "before_end_date = clusters_df[\"date_announced\"] <= end_date\n",
    "between_two_dates = after_start_date & before_end_date\n",
    "clusters_df = clusters_df.loc[between_two_dates]\n",
    "clusters_df['date'] = clusters_df.date_announced\n",
    "clusters_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_count_by_state = clusters_df.groupby([clusters_df['state']]).count().loc[['Johor','Pahang','Kedah','Selangor']]['cluster']\n",
    "clusters_df = clusters_df.groupby([clusters_df['state']]).sum().loc[['Johor','Pahang','Kedah','Selangor']]\n",
    "clusters_df['cluster_total'] = cluster_count_by_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Identify Missing Value\n",
    "</p> Visualize the number of missing values as a bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.bar(clusters_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Identify Outliers\n",
    "</p> Visualize the data using box plot, check the distribution of data and outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(15, 5), sharey=True)\n",
    "# fig.suptitle('Outliers Visualization')\n",
    "plt.subplots_adjust(left=None, bottom= 0.1, right=None, top=2, wspace=0.2, hspace=0.6)\n",
    "\n",
    "sns.boxplot(data=clusters_df,x=clusters_df[\"cases_new\"],ax=axes[0][0])\n",
    "axes[0][0].set_title('cases_new')\n",
    "\n",
    "sns.boxplot(data=clusters_df,x=clusters_df[\"cases_total\"],ax=axes[0][1])\n",
    "axes[0][1].set_title('cases_total')\n",
    "\n",
    "sns.boxplot(data=clusters_df,x=clusters_df[\"cases_active\"],ax=axes[0][2])\n",
    "axes[0][2].set_title('cases_active')\n",
    "\n",
    "sns.boxplot(data=clusters_df,x=clusters_df[\"tests\"],ax=axes[1][0])\n",
    "axes[1][0].set_title('tests')\n",
    "\n",
    "sns.boxplot(data=clusters_df,x=clusters_df[\"icu\"],ax=axes[1][1])\n",
    "axes[1][1].set_title('icu')\n",
    "\n",
    "sns.boxplot(data=clusters_df,x=clusters_df[\"deaths\"],ax=axes[1][2])\n",
    "axes[1][2].set_title('deaths')\n",
    "\n",
    "sns.boxplot(data=clusters_df,x=clusters_df[\"recovered\"],ax=axes[2][0])\n",
    "axes[2][0].set_title('recovered')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis for Malaysia Tests Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "malaysia_tests_df = pd.read_csv(malaysia_tests_dir)\n",
    "after_start_date = malaysia_tests_df[\"date\"] >= start_date\n",
    "before_end_date = malaysia_tests_df[\"date\"] <= end_date\n",
    "between_two_dates = after_start_date & before_end_date\n",
    "malaysia_tests_df = malaysia_tests_df.loc[between_two_dates]\n",
    "malaysia_tests_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "malaysia_tests_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "malaysia_tests_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "malaysia_tests_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Identify Missing Value\n",
    "</p> Visualize the number of missing values as a bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.bar(malaysia_tests_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Identify Outliers\n",
    "</p> Visualize the data using box plot, check the distribution of data and outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5), sharey=True)\n",
    "# fig.suptitle('Outliers Visualization')\n",
    "plt.subplots_adjust(left=None, bottom= 0.1, right=None, top=0.5, wspace=0.2, hspace=0.6)\n",
    "\n",
    "sns.boxplot(data=malaysia_tests_df, x = malaysia_tests_df[\"rtk-ag\"],ax=axes[0])\n",
    "axes[0].set_title('rtk-ag')\n",
    "\n",
    "sns.boxplot(data=malaysia_tests_df,x = malaysia_tests_df[\"pcr\"],ax=axes[1])\n",
    "axes[1].set_title('pcr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis for State Tests Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_tests_df = pd.read_csv(states_tests_dir)\n",
    "after_start_date = states_tests_df[\"date\"] >= start_date\n",
    "before_end_date = states_tests_df[\"date\"] <= end_date\n",
    "between_two_dates = after_start_date & before_end_date\n",
    "states_tests_df = states_tests_df.loc[between_two_dates]\n",
    "states_tests_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_tests_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_tests_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_tests_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Identify Missing Value\n",
    "</p> Visualize the number of missing values as a bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.bar(states_tests_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Identify Outliers\n",
    "</p> Visualize the data using box plot, check the distribution of data and outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5), sharey=True)\n",
    "# fig.suptitle('Outliers Visualization')\n",
    "plt.subplots_adjust(left=None, bottom= 0.1, right=None, top=0.5, wspace=0.2, hspace=0.6)\n",
    "\n",
    "sns.boxplot(data=states_tests_df, x = states_tests_df[\"rtk-ag\"],ax=axes[0])\n",
    "axes[0].set_title('rtk-ag')\n",
    "\n",
    "sns.boxplot(data=states_tests_df,x = states_tests_df[\"pcr\"],ax=axes[1])\n",
    "axes[1].set_title('pcr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis for PKRC Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkrc_df = pd.read_csv(pkrc_dir)\n",
    "after_start_date = pkrc_df[\"date\"] >= start_date\n",
    "before_end_date = pkrc_df[\"date\"] <= end_date\n",
    "between_two_dates = after_start_date & before_end_date\n",
    "pkrc_df = pkrc_df.loc[between_two_dates]\n",
    "pkrc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkrc_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkrc_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkrc_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Identify Missing Value\n",
    "</p> Visualize the number of missing values as a bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.bar(pkrc_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Identify Outliers\n",
    "</p> Visualize the data using box plot, check the distribution of data and outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 3, figsize=(15, 5), sharey=True)\n",
    "# fig.suptitle('Outliers Visualization')\n",
    "plt.subplots_adjust(left=None, bottom= 0.1, right=None, top=2, wspace=0.2, hspace=0.6)\n",
    "\n",
    "sns.boxplot(data=pkrc_df, x = pkrc_df[\"beds\"],ax=axes[0][0])\n",
    "axes[0][0].set_title('beds')\n",
    "sns.boxplot(data=pkrc_df,x = pkrc_df[\"admitted_pui\"],ax=axes[0][1])\n",
    "axes[0][1].set_title('admitted_pui')\n",
    "sns.boxplot(data=pkrc_df, x = pkrc_df[\"admitted_covid\"],ax=axes[0][2])\n",
    "axes[0][2].set_title(\"admitted_covid\")\n",
    "sns.boxplot(data=pkrc_df,x = pkrc_df[\"admitted_total\"],ax=axes[1][0])\n",
    "axes[1][0].set_title('admitted_total')\n",
    "sns.boxplot(data=pkrc_df, x = pkrc_df[\"discharge_pui\"],ax=axes[1][1])\n",
    "axes[1][1].set_title('discharge_pui')\n",
    "sns.boxplot(data=pkrc_df,x = pkrc_df[\"discharge_covid\"],ax=axes[1][2])\n",
    "axes[1][2].set_title('discharge_covid')\n",
    "sns.boxplot(data=pkrc_df, x = pkrc_df[\"discharge_total\"],ax=axes[2][0])\n",
    "axes[2][0].set_title('discharge_total')\n",
    "sns.boxplot(data=pkrc_df,x = pkrc_df[\"pkrc_covid\"],ax=axes[2][1])\n",
    "axes[2][1].set_title('pkrc_covid')\n",
    "sns.boxplot(data=pkrc_df, x = pkrc_df[\"pkrc_pui\"],ax=axes[2][2])\n",
    "axes[2][2].set_title('pkrc_pui')\n",
    "sns.boxplot(data=pkrc_df,x = pkrc_df[\"pkrc_noncovid\"],ax=axes[3][0])\n",
    "axes[2][0].set_title('pkrc_noncovid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analaysis for Mysejahtera CheckIn Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkIn_df = pd.read_csv(checkIn_dir)\n",
    "after_start_date = checkIn_df[\"date\"] >= start_date\n",
    "before_end_date = checkIn_df[\"date\"] <= end_date\n",
    "between_two_dates = after_start_date & before_end_date\n",
    "checkIn_df = checkIn_df.loc[between_two_dates]\n",
    "checkIn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkIn_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkIn_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkIn_null_df=pd.DataFrame({'Column':checkIn_df.isna().sum().index, 'Count of Null Values':checkIn_df.isna().sum().values})  \n",
    "checkIn_null_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Identify Missing Value\n",
    "</p> Visualize the number of missing values as a bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.bar(checkIn_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Identify Outliers\n",
    "</p> Visualize the data using box plot, check the distribution of data and outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5), sharey=True)\n",
    "# fig.suptitle('Outliers Visualization')\n",
    "plt.subplots_adjust(left=None, bottom= 0.1, right=None, top=0.5, wspace=0.2, hspace=0.6)\n",
    "\n",
    "sns.boxplot(data=checkIn_df, x = checkIn_df[\"checkins\"],ax=axes[0])\n",
    "axes[0].set_title('checkins')\n",
    "sns.boxplot(data=checkIn_df,x = checkIn_df[\"unique_ind\"],ax=axes[1])\n",
    "axes[1].set_title('unique_ind')\n",
    "sns.boxplot(data=checkIn_df, x = checkIn_df[\"unique_loc\"],ax=axes[2])\n",
    "axes[1].set_title('unique_loc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploratory Data Analysis for Hospital Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_df = pd.read_csv(hospital_dir)\n",
    "after_start_date = hospital_df[\"date\"] >= start_date\n",
    "before_end_date = hospital_df[\"date\"] <= end_date\n",
    "between_two_dates = after_start_date & before_end_date\n",
    "hospital_df = hospital_df.loc[between_two_dates]\n",
    "hospital_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_df_null_df=pd.DataFrame({'Column':hospital_df.isna().sum().index, 'Count of Null Values':hospital_df.isna().sum().values})  \n",
    "hospital_df_null_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Identify Missing Value\n",
    "</p> Visualize the number of missing values as a bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.bar(hospital_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Identify Outliers\n",
    "</p> Visualize the data using box plot, check the distribution of data and outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 3, figsize=(15, 5), sharey=True)\n",
    "# fig.suptitle('Outliers Visualization')\n",
    "plt.subplots_adjust(left=None, bottom= 0.1, right=None, top=2, wspace=0.2, hspace=0.6)\n",
    "\n",
    "# beds\tbeds_covid\tbeds_noncrit\tadmitted_pui\tadmitted_covid\tadmitted_total\tdischarged_pui\tdischarged_covid\tdischarged_total\thosp_covid\t\n",
    "# hosp_pui\thosp_noncovid\n",
    "\n",
    "sns.boxplot(data=hospital_df, x = hospital_df[\"beds\"],ax=axes[0][0])\n",
    "axes[0][0].set_title('beds')\n",
    "sns.boxplot(data=hospital_df,x = hospital_df[\"beds_covid\"],ax=axes[0][1])\n",
    "axes[0][1].set_title('beds_covid')\n",
    "sns.boxplot(data=hospital_df, x = hospital_df[\"beds_noncrit\"],ax=axes[0][2])\n",
    "axes[0][2].set_title('beds_noncrit')\n",
    "sns.boxplot(data=hospital_df, x = hospital_df[\"admitted_pui\"],ax=axes[1][0])\n",
    "axes[1][0].set_title('admitted_pui')\n",
    "sns.boxplot(data=hospital_df,x = hospital_df[\"admitted_covid\"],ax=axes[1][1])\n",
    "axes[1][1].set_title('admitted_covid')\n",
    "sns.boxplot(data=hospital_df, x = hospital_df[\"admitted_total\"],ax=axes[1][2])\n",
    "axes[1][2].set_title('admitted_total')\n",
    "sns.boxplot(data=hospital_df, x = hospital_df[\"discharged_pui\"],ax=axes[2][0])\n",
    "axes[2][0].set_title('discharged_pui')\n",
    "sns.boxplot(data=hospital_df,x = hospital_df[\"discharged_covid\"],ax=axes[2][1])\n",
    "axes[2][1].set_title('discharged_covid')\n",
    "sns.boxplot(data=hospital_df, x = hospital_df[\"discharged_total\"],ax=axes[2][2])\n",
    "axes[2][2].set_title('discharged_total')\n",
    "sns.boxplot(data=hospital_df, x = hospital_df[\"hosp_covid\"],ax=axes[3][0])\n",
    "axes[3][0].set_title('hosp_covid')\n",
    "sns.boxplot(data=hospital_df,x = hospital_df[\"hosp_pui\"],ax=axes[3][1])\n",
    "axes[3][1].set_title('hosp_pui')\n",
    "sns.boxplot(data=hospital_df, x = hospital_df[\"hosp_noncovid\"],ax=axes[3][2])\n",
    "axes[3][2].set_title('hosp_noncovid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='FireBrick'>Question 3 (ii)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing with One-Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before finding the relationship between the states, we perform One-Hot encoding to preprocess the state cases dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'state_case_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-1b29bb6046e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstate_case_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_case_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'state'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mstate_case_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'state_case_df' is not defined"
     ]
    }
   ],
   "source": [
    "state_case_df = pd.get_dummies(state_case_df, prefix='', columns=['state'])\n",
    "state_case_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_case_import_df = state_case_df.loc[:,'_Johor':].multiply(state_case_df[\"cases_import\"], axis=\"index\")\n",
    "state_case_new_df = state_case_df.loc[:,'_Johor':].multiply(state_case_df[\"cases_new\"], axis=\"index\")\n",
    "state_case_recovered_df = state_case_df.loc[:,'_Johor':].multiply(state_case_df[\"cases_recovered\"], axis=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_case_import_df.columns = state_case_import_df.columns.str[1:]\n",
    "state_case_import_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_case_import_df['date'] = date\n",
    "state_case_new_df['date'] = date\n",
    "state_case_recovered_df['date'] = date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_case_import_df = state_case_import_df.groupby([state_case_import_df['date']]).sum()\n",
    "state_case_new_df = state_case_new_df.groupby([state_case_new_df['date']]).sum()\n",
    "state_case_recovered_df = state_case_recovered_df.groupby([state_case_recovered_df['date']]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = state_case_new_df.corr()\n",
    "fig, ax = plt.subplots(figsize=(20,10))  \n",
    "ax = sns.heatmap(\n",
    "    corr, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True,\n",
    "    annot = True,\n",
    "    linewidths = 2\n",
    ")\n",
    "\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ");\n",
    "ax.set_title('New Case Correlation Heatmap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='FireBrick'>Question 3 (iii)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-processing the needed datasets : **Cluster, State Cases, Testsï¼ŒMysejahtera checkins, PKRC, Hospital** </p> We use data of 4 states in Malaysia to perform feature selection : **Pahang, Johor, Kedah, Selangor**. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = [\"Pahang\",\"Kedah\",\"Johor\",\"Selangor\"]\n",
    "clusters_df = clusters_df.loc[clusters_df['state'].isin(state)]\n",
    "clusters_df['date'] = clusters_df.date_announced\n",
    "state_case_df = state_case_df.loc[state_case_df['state'].isin(state)]\n",
    "states_tests_df = states_tests_df.loc[states_tests_df['state'].isin(state)]\n",
    "mysejahtera = mysejahtera.loc[mysejahtera['state'].isin(state)]\n",
    "mysejahtera_checkins[\"date\"] = mysejahtera.date\n",
    "pkrc_df = pkrc_df.loc[pkrc_df['state'].isin(state)]\n",
    "pkrc_df['date'] = pkrc_df.date\n",
    "pkrc_df = pkrc_df.add_suffix('_pkrc')\n",
    "hospital_df = hospital_df.loc[hospital_df['state'].isin(state)]\n",
    "hospital_df['date'] = hospital_df.date\n",
    "hospital_df = hospital_df.add_suffix('_hospital')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster Dataset\n",
    "## One-Hot Encoding\n",
    "clusters_df = pd.get_dummies(clusters_df, prefix='cluster', columns=['category'])\n",
    "## Drop unused columns\n",
    "clusters_df.drop(['cases_new','cases_total','cases_active','tests','icu','deaths','recovered'], axis=1, inplace=True)\n",
    "## Group by date and state\n",
    "clusters_df=clusters_df.groupby(['date_announced','state']).sum()clusters_df=clusters_df.groupby(['date_announced','state']).sum()\n",
    "clusters_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State Cases Dataset\n",
    "## Group by date and state\n",
    "state_case_df=state_case_df.groupby(['date','state']).sum()\n",
    "state_case_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State Tests Dataset\n",
    "## Group by date and state\n",
    "states_tests_df=states_tests_df.groupby(['date','state']).sum()\n",
    "states_tests_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MySejahtera Checkins Dataset\n",
    "## One-Hot Encoding\n",
    "mysejahtera = pd.get_dummies(mysejahtera, prefix='', columns=['state'])\n",
    "mysejahtera_checkins = mysejahtera.loc[:,'_Johor':].multiply(mysejahtera[\"checkins\"], axis=\"index\")\n",
    "mysejahtera_checkins.columns = mysejahtera_checkins.columns.str[1:]\n",
    "## Group by date and state\n",
    "mysejahtera_checkins = mysejahtera_checkins.groupby([mysejahtera_checkins['date']]).sum()\n",
    "mysejahtera_checkins.columns.name = 'state'\n",
    "mysejahtera_checkins = mysejahtera_checkins.stack()\n",
    "mysejahtera_checkins.name = 'Checkins number'\n",
    "mysejahtera_checkins = mysejahtera_checkins.reset_index()\n",
    "mysejahtera_checkins = mysejahtera_checkins.groupby(['date','state']).sum()\n",
    "mysejahtera_checkins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PKRC Dataset\n",
    "## Group by date and state\n",
    "pkrc_df = pkrc_df.groupby(['date_pkrc','state_pkrc']).sum()\n",
    "pkrc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hospital Dataset\n",
    "## Group by date and state\n",
    "hospital_df = hospital_df.groupby(['date_hospital','state_hospital']).sum()\n",
    "hospital_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat([clusters_df, states_tests_df, state_case_df,mysejahtera_checkins,pkrc_df,hospital_df], axis=1)\n",
    "df_final.fillna(0,inplace=True)\n",
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Boruta Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rslt_df_ph = df_final[df_final['state'] == \"Pahang\"]\n",
    "rslt_df_kd = df_final[df_final['state'] == \"Kedah\"]\n",
    "rslt_df_jh = df_final[df_final['state'] == \"Johor\"]\n",
    "rslt_df_sl = df_final[df_final['state'] == \"Selangor\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_jobs=-1, class_weight=\"balanced\",criterion = \"entropy\")\n",
    "rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boruta Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranking(ranks, names, order=1):\n",
    "    minmax = MinMaxScaler()\n",
    "    ranks = minmax.fit_transform(order*np.array([ranks]).T).T[0]\n",
    "    ranks = map(lambda x: round(x,2), ranks)\n",
    "    return dict(zip(names, ranks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_selector = BorutaPy(rf, n_estimators=\"auto\", random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_final\n",
    "y = df.cases_new\n",
    "X = df.drop([\"cases_new\",\"date\",\"state\"], 1)\n",
    "colnames = X.columns\n",
    "feat_selector.fit(X.values, y.values.ravel()\n",
    "print(feat_selector.support_)\n",
    "print(feat_selector.ranking_)\n",
    "boruta_score = ranking(list(map(float, feat_selector.ranking_)), colnames, order=-1)\n",
    "boruta_score = pd.DataFrame(list(boruta_score.items()), columns=['Features', 'Score']) \n",
    "boruta_score = boruta_score.sort_values(\"Score\",ascending = False)\n",
    "                  print('---------Top 5----------')\n",
    "display(rfe_score.head(5))\n",
    "sns_boruta_plot = sns.catplot(x=\"Score\", y=\"Features\", data = boruta_score[0:35], kind = \"bar\", \n",
    "               height=14, aspect=1.5, palette='RdYlBu')\n",
    "plt.title(\"Boruta Top Features for All 4 states\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = rslt_df_ph\n",
    "y = df.cases_new\n",
    "X = df.drop([\"cases_new\",\"date\",\"state\"], 1)\n",
    "colnames = X.columns\n",
    "feat_selector.fit(X.values, y.values.ravel()\n",
    "print(feat_selector.support_)\n",
    "print(feat_selector.ranking_)\n",
    "boruta_score = ranking(list(map(float, feat_selector.ranking_)), colnames, order=-1)\n",
    "boruta_score = pd.DataFrame(list(boruta_score.items()), columns=['Features', 'Score']) \n",
    "boruta_score = boruta_score.sort_values(\"Score\",ascending = False)\n",
    "                  print('---------Top 5----------')\n",
    "display(rfe_score.head(5))\n",
    "sns_boruta_plot = sns.catplot(x=\"Score\", y=\"Features\", data = boruta_score[0:35], kind = \"bar\", \n",
    "               height=14, aspect=1.5, palette='RdYlBu')\n",
    "plt.title(\"Boruta Top Features for Pahang\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =rslt_df_kd\n",
    "y = df.cases_new\n",
    "X = df.drop([\"cases_new\",\"date\",\"state\"], 1)\n",
    "colnames = X.columns\n",
    "feat_selector.fit(X.values, y.values.ravel()\n",
    "print(feat_selector.support_)\n",
    "print(feat_selector.ranking_)\n",
    "boruta_score = ranking(list(map(float, feat_selector.ranking_)), colnames, order=-1)\n",
    "boruta_score = pd.DataFrame(list(boruta_score.items()), columns=['Features', 'Score']) \n",
    "boruta_score = boruta_score.sort_values(\"Score\",ascending = False)\n",
    "                  print('---------Top 5----------')\n",
    "display(rfe_score.head(5))\n",
    "sns_boruta_plot = sns.catplot(x=\"Score\", y=\"Features\", data = boruta_score[0:35], kind = \"bar\", \n",
    "               height=14, aspect=1.5, palette='RdYlBu')\n",
    "plt.title(\"Boruta Top Features for Kedah\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = rslt_df_jh\n",
    "y = df.cases_new\n",
    "X = df.drop([\"cases_new\",\"date\",\"state\"], 1)\n",
    "colnames = X.columns\n",
    "feat_selector.fit(X.values, y.values.ravel()\n",
    "print(feat_selector.support_)\n",
    "print(feat_selector.ranking_)\n",
    "boruta_score = ranking(list(map(float, feat_selector.ranking_)), colnames, order=-1)\n",
    "boruta_score = pd.DataFrame(list(boruta_score.items()), columns=['Features', 'Score']) \n",
    "boruta_score = boruta_score.sort_values(\"Score\",ascending = False)\n",
    "                  print('---------Top 5----------')\n",
    "display(rfe_score.head(5))\n",
    "sns_boruta_plot = sns.catplot(x=\"Score\", y=\"Features\", data = boruta_score[0:35], kind = \"bar\", \n",
    "               height=14, aspect=1.5, palette='RdYlBu')\n",
    "plt.title(\"Boruta Top Features for Johor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = rslt_df_sl\n",
    "y = df.cases_new\n",
    "X = df.drop([\"cases_new\",\"date\",\"state\"], 1)\n",
    "colnames = X.columns\n",
    "feat_selector.fit(X.values, y.values.ravel()\n",
    "print(feat_selector.support_)\n",
    "print(feat_selector.ranking_)\n",
    "boruta_score = ranking(list(map(float, feat_selector.ranking_)), colnames, order=-1)\n",
    "boruta_score = pd.DataFrame(list(boruta_score.items()), columns=['Features', 'Score']) \n",
    "boruta_score = boruta_score.sort_values(\"Score\",ascending = False)\n",
    "                  print('---------Top 5----------')\n",
    "display(rfe_score.head(5))\n",
    "sns_boruta_plot = sns.catplot(x=\"Score\", y=\"Features\", data = boruta_score[0:35], kind = \"bar\", \n",
    "               height=14, aspect=1.5, palette='RdYlBu')\n",
    "plt.title(\"Boruta Top Features for Selangor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform RFE Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_final\n",
    "y = df.cases_new\n",
    "X = df.drop([\"cases_new\",\"date\",\"state\"], 1)\n",
    "rfe = RFECV(rf, min_features_to_select = 1, cv =2)\n",
    "rfe.fit(X, y)\n",
    "rfe_score = ranking(list(map(float, rfe.ranking_)), colnames, order=-1)\n",
    "rfe_score = pd.DataFrame(list(rfe_score.items()), columns=['Features', 'Score'])\n",
    "rfe_score = rfe_score.sort_values(\"Score\", ascending = False)\n",
    "print('---------Top 5----------')\n",
    "display(rfe_score.head(5))\n",
    "sns_rfe_plot = sns.catplot(x=\"Score\", y=\"Features\", data = rfe_score[0:35], kind = \"bar\", \n",
    "               height=14, aspect=1.9, palette='coolwarm')\n",
    "plt.title(\"RFE Features Ranking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = rslt_df_ph\n",
    "y = df.cases_new\n",
    "X = df.drop([\"cases_new\",\"date\",\"state\"], 1)\n",
    "rfe = RFECV(rf, min_features_to_select = 1, cv =2)\n",
    "rfe.fit(X, y)\n",
    "rfe_score = ranking(list(map(float, rfe.ranking_)), colnames, order=-1)\n",
    "rfe_score = pd.DataFrame(list(rfe_score.items()), columns=['Features', 'Score'])\n",
    "rfe_score = rfe_score.sort_values(\"Score\", ascending = False)\n",
    "print('---------Top 5----------')\n",
    "display(rfe_score.head(5))\n",
    "sns_rfe_plot = sns.catplot(x=\"Score\", y=\"Features\", data = rfe_score[0:35], kind = \"bar\", \n",
    "               height=14, aspect=1.9, palette='coolwarm')\n",
    "plt.title(\"RFE Features Ranking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = rslt_df_kd\n",
    "y = df.cases_new\n",
    "X = df.drop([\"cases_new\",\"date\",\"state\"], 1)\n",
    "rfe = RFECV(rf, min_features_to_select = 1, cv =2)\n",
    "rfe.fit(X, y)\n",
    "rfe_score = ranking(list(map(float, rfe.ranking_)), colnames, order=-1)\n",
    "rfe_score = pd.DataFrame(list(rfe_score.items()), columns=['Features', 'Score'])\n",
    "rfe_score = rfe_score.sort_values(\"Score\", ascending = False)\n",
    "print('---------Top 5----------')\n",
    "display(rfe_score.head(5))\n",
    "sns_rfe_plot = sns.catplot(x=\"Score\", y=\"Features\", data = rfe_score[0:35], kind = \"bar\", \n",
    "               height=14, aspect=1.9, palette='coolwarm')\n",
    "plt.title(\"RFE Features Ranking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = rslt_df_jh\n",
    "y = df.cases_new\n",
    "X = df.drop([\"cases_new\",\"date\",\"state\"], 1)\n",
    "rfe = RFECV(rf, min_features_to_select = 1, cv =2)\n",
    "rfe.fit(X, y)\n",
    "rfe_score = ranking(list(map(float, rfe.ranking_)), colnames, order=-1)\n",
    "rfe_score = pd.DataFrame(list(rfe_score.items()), columns=['Features', 'Score'])\n",
    "rfe_score = rfe_score.sort_values(\"Score\", ascending = False)\n",
    "print('---------Top 5----------')\n",
    "display(rfe_score.head(5))\n",
    "sns_rfe_plot = sns.catplot(x=\"Score\", y=\"Features\", data = rfe_score[0:35], kind = \"bar\", \n",
    "               height=14, aspect=1.9, palette='coolwarm')\n",
    "plt.title(\"RFE Features Ranking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = rslt_df_sl\n",
    "y = df.cases_new\n",
    "X = df.drop([\"cases_new\",\"date\",\"state\"], 1)\n",
    "rfe = RFECV(rf, min_features_to_select = 1, cv =2)\n",
    "rfe.fit(X, y)\n",
    "#model = LogisticRegression(solver='lbfgs')\n",
    "#rfe = RFE(model, 3)\n",
    "#rfe.fit(X, y)\n",
    "rfe_score = ranking(list(map(float, rfe.ranking_)), colnames, order=-1)\n",
    "rfe_score = pd.DataFrame(list(rfe_score.items()), columns=['Features', 'Score'])\n",
    "rfe_score = rfe_score.sort_values(\"Score\", ascending = False)\n",
    "print('---------Top 5----------')\n",
    "display(rfe_score.head(5))\n",
    "sns_rfe_plot = sns.catplot(x=\"Score\", y=\"Features\", data = rfe_score[0:35], kind = \"bar\", \n",
    "               height=14, aspect=1.9, palette='coolwarm')\n",
    "plt.title(\"RFE Features Ranking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='FireBrick'>Question 3 (iv)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_final.drop(['cases_new','date','state'], axis=1)  #predict newcases\n",
    "y = df_final['cases_new']  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 2)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Linear Regressor\")\n",
    "print(\"Median absolute error : \" + median_absolute_error(y_test, y_pred))\n",
    "print(\"Mean absolute error : \" + mean_absolute_error(y_test, y_pred))\n",
    "print(\"Mean squared error : \" + mean_squared_error(y_test, y_pred))\n",
    "print(\"Root mean square error : \" + np.sqrt(mean_squared_error(y_test,y_pred)))\n",
    "print(\"R squared: \" + r2_score(y_test,y_pred))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 2)\n",
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(X, y)\n",
    "y_pred = rfr.predict(X_test)\n",
    "print(\"Random Forest Regressor\")\n",
    "print(\"Median absolute error : \" + median_absolute_error(y_test, y_pred))\n",
    "print(\"Mean absolute error : \" + mean_absolute_error(y_test, y_pred))\n",
    "print(\"Mean squared error : \" + mean_squared_error(y_test, y_pred))\n",
    "print(\"Root mean square error : \" + np.sqrt(mean_squared_error(y_test,y_pred)))\n",
    "print(\"R squared: \" + r2_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = rslt_df_ph.drop(['cases_new','date','state'], axis=1)  #predict newcases\n",
    "y = rslt_df_ph['cases_new']  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 2)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Linear Regressor\")\n",
    "print(\"Median absolute error : \" + median_absolute_error(y_test, y_pred))\n",
    "print(\"Mean absolute error : \" + mean_absolute_error(y_test, y_pred))\n",
    "print(\"Mean squared error : \" + mean_squared_error(y_test, y_pred))\n",
    "print(\"Root mean square error : \" + np.sqrt(mean_squared_error(y_test,y_pred)))\n",
    "print(\"R squared: \" + r2_score(y_test,y_pred))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 2)\n",
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(X, y)\n",
    "y_pred = rfr.predict(X_test)\n",
    "print(\"Random Forest Regressor\")\n",
    "print(\"Median absolute error : \" + median_absolute_error(y_test, y_pred))\n",
    "print(\"Mean absolute error : \" + mean_absolute_error(y_test, y_pred))\n",
    "print(\"Mean squared error : \" + mean_squared_error(y_test, y_pred))\n",
    "print(\"Root mean square error : \" + np.sqrt(mean_squared_error(y_test,y_pred)))\n",
    "print(\"R squared: \" + r2_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = rslt_df_kd.drop(['cases_new','date','state'], axis=1)  #predict newcases\n",
    "y = rslt_df_kd['cases_new']  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 2)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Linear Regressor\")\n",
    "print(\"Median absolute error : \" + median_absolute_error(y_test, y_pred))\n",
    "print(\"Mean absolute error : \" + mean_absolute_error(y_test, y_pred))\n",
    "print(\"Mean squared error : \" + mean_squared_error(y_test, y_pred))\n",
    "print(\"Root mean square error : \" + np.sqrt(mean_squared_error(y_test,y_pred)))\n",
    "print(\"R squared: \" + r2_score(y_test,y_pred))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 2)\n",
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(X, y)\n",
    "y_pred = rfr.predict(X_test)\n",
    "print(\"Random Forest Regressor\")\n",
    "print(\"Median absolute error : \" + median_absolute_error(y_test, y_pred))\n",
    "print(\"Mean absolute error : \" + mean_absolute_error(y_test, y_pred))\n",
    "print(\"Mean squared error : \" + mean_squared_error(y_test, y_pred))\n",
    "print(\"Root mean square error : \" + np.sqrt(mean_squared_error(y_test,y_pred)))\n",
    "print(\"R squared: \" + r2_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = rslt_df_jh.drop(['cases_new','date','state'], axis=1)  #predict newcases\n",
    "y = rslt_df_jh['cases_new']  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 2)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Linear Regressor\")\n",
    "print(\"Median absolute error : \" + median_absolute_error(y_test, y_pred))\n",
    "print(\"Mean absolute error : \" + mean_absolute_error(y_test, y_pred))\n",
    "print(\"Mean squared error : \" + mean_squared_error(y_test, y_pred))\n",
    "print(\"Root mean square error : \" + np.sqrt(mean_squared_error(y_test,y_pred)))\n",
    "print(\"R squared: \" + r2_score(y_test,y_pred))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 2)\n",
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(X, y)\n",
    "y_pred = rfr.predict(X_test)\n",
    "print(\"Random Forest Regressor\")\n",
    "print(\"Median absolute error : \" + median_absolute_error(y_test, y_pred))\n",
    "print(\"Mean absolute error : \" + mean_absolute_error(y_test, y_pred))\n",
    "print(\"Mean squared error : \" + mean_squared_error(y_test, y_pred))\n",
    "print(\"Root mean square error : \" + np.sqrt(mean_squared_error(y_test,y_pred)))\n",
    "print(\"R squared: \" + r2_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = rslt_df_sl.drop(['cases_new','date','state'], axis=1)  #predict newcases\n",
    "y = rslt_df_sl['cases_new']  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 2)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Linear Regressor\")\n",
    "print(\"Median absolute error : \" + median_absolute_error(y_test, y_pred))\n",
    "print(\"Mean absolute error : \" + mean_absolute_error(y_test, y_pred))\n",
    "print(\"Mean squared error : \" + mean_squared_error(y_test, y_pred))\n",
    "print(\"Root mean square error : \" + np.sqrt(mean_squared_error(y_test,y_pred)))\n",
    "print(\"R squared: \" + r2_score(y_test,y_pred))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 2)\n",
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(X, y)\n",
    "y_pred = rfr.predict(X_test)\n",
    "print(\"Random Forest Regressor\")\n",
    "print(\"Median absolute error : \" + median_absolute_error(y_test, y_pred))\n",
    "print(\"Mean absolute error : \" + mean_absolute_error(y_test, y_pred))\n",
    "print(\"Mean squared error : \" + mean_squared_error(y_test, y_pred))\n",
    "print(\"Root mean square error : \" + np.sqrt(mean_squared_error(y_test,y_pred)))\n",
    "print(\"R squared: \" + r2_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBinsRange(df):  \n",
    "        data = df['cases_new'].values\n",
    "        # First quartile (Q1)\n",
    "        Q1 = np.percentile(data, 25, interpolation = 'midpoint')\n",
    "        # Third quartile (Q3)\n",
    "        Q3 = np.percentile(data, 75, interpolation = 'midpoint')\n",
    "\n",
    "        return [np.min(data),Q1,Q3,np.inf]\n",
    "\n",
    "labels = ['Low','Medium','High']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Binning\n",
    "df_final['cases_new_category'] = (pd.cut(df_final['cases_new'].values, bins=getBinsRange(df_final),labels=labels, include_lowest=True))\n",
    "X = df_final.drop(['cases_new','date','state','cases_new_category'], axis=1)\n",
    "y = df_final.cases_new_category # Target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1)\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=5, splitter='random') #pruning the tree by setting the depth\n",
    "# Train Decision Tree Classifer*\n",
    "clf = clf.fit(X_train,y_train)\n",
    "#Predict the response for test dataset*\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Decision Tree Classifier\")\n",
    "print('Precision= {:.2f}'.format(precision_score(y_test, y_pred, average=\"weighted\")))\n",
    "print('Recall= {:.2f}'. format(recall_score(y_test, y_pred, average=\"weighted\")))\n",
    "print('F1= {:.2f}'. format(f1_score(y_test, y_pred, average=\"weighted\")))\n",
    "print('Accuracy= {:.2f}'. format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 2)\n",
    "model = GaussianNB()\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Gaussian Naie Bayes\")\n",
    "print('Precision= {:.2f}'.format(precision_score(y_test, y_pred, average=\"weighted\")))\n",
    "print('Recall= {:.2f}'. format(recall_score(y_test, y_pred, average=\"weighted\")))\n",
    "print('F1= {:.2f}'. format(f1_score(y_test, y_pred, average=\"weighted\")))\n",
    "print('Accuracy= {:.2f}'. format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Binning\n",
    "rslt_df_ph['cases_new_category'] = (pd.cut(rslt_df_ph['cases_new'].values, bins=getBinsRange(rslt_df_ph),labels=labels, include_lowest=True))\n",
    "X = rslt_df_ph.drop(['cases_new','date','state','cases_new_category'], axis=1)\n",
    "y = rslt_df_ph.cases_new_category # Target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1)\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=5, splitter='random') #pruning the tree by setting the depth\n",
    "# Train Decision Tree Classifer*\n",
    "clf = clf.fit(X_train,y_train)\n",
    "#Predict the response for test dataset*\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Decision Tree Classifier\")\n",
    "print('Precision= {:.2f}'.format(precision_score(y_test, y_pred, average=\"weighted\")))\n",
    "print('Recall= {:.2f}'. format(recall_score(y_test, y_pred, average=\"weighted\")))\n",
    "print('F1= {:.2f}'. format(f1_score(y_test, y_pred, average=\"weighted\")))\n",
    "print('Accuracy= {:.2f}'. format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 2)\n",
    "model = GaussianNB()\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Gaussian Naie Bayes\")\n",
    "print('Precision= {:.2f}'.format(precision_score(y_test, y_pred, average=\"weighted\")))\n",
    "print('Recall= {:.2f}'. format(recall_score(y_test, y_pred, average=\"weighted\")))\n",
    "print('F1= {:.2f}'. format(f1_score(y_test, y_pred, average=\"weighted\")))\n",
    "print('Accuracy= {:.2f}'. format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Binning\n",
    "rslt_df_kd['cases_new_category'] = (pd.cut(rslt_df_kd['cases_new'].values, bins=getBinsRange(rslt_df_kd),labels=labels, include_lowest=True))\n",
    "X = rslt_df_kd.drop(['cases_new','date','state','cases_new_category'], axis=1)\n",
    "y = rslt_df_kd.cases_new_category # Target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1)\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=5, splitter='random') #pruning the tree by setting the depth\n",
    "# Train Decision Tree Classifer*\n",
    "clf = clf.fit(X_train,y_train)\n",
    "#Predict the response for test dataset*\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Decision Tree Classifier\")\n",
    "print('Precision= {:.2f}'.format(precision_score(y_test, y_pred, average=\"weighted\")))\n",
    "print('Recall= {:.2f}'. format(recall_score(y_test, y_pred, average=\"weighted\")))\n",
    "print('F1= {:.2f}'. format(f1_score(y_test, y_pred, average=\"weighted\")))\n",
    "print('Accuracy= {:.2f}'. format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 2)\n",
    "model = GaussianNB()\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Gaussian Naie Bayes\")\n",
    "print('Precision= {:.2f}'.format(precision_score(y_test, y_pred, average=\"weighted\")))\n",
    "print('Recall= {:.2f}'. format(recall_score(y_test, y_pred, average=\"weighted\")))\n",
    "print('F1= {:.2f}'. format(f1_score(y_test, y_pred, average=\"weighted\")))\n",
    "print('Accuracy= {:.2f}'. format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Binning\n",
    "rslt_df_jh['cases_new_category'] = (pd.cut(rslt_df_jh['cases_new'].values, bins=getBinsRange(rslt_df_jh),labels=labels, include_lowest=True))\n",
    "X = rslt_df_jh.drop(['cases_new','date','state','cases_new_category'], axis=1)\n",
    "y = rslt_df_jh.cases_new_category # Target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1)\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=5, splitter='random') #pruning the tree by setting the depth\n",
    "# Train Decision Tree Classifer*\n",
    "clf = clf.fit(X_train,y_train)\n",
    "#Predict the response for test dataset*\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Decision Tree Classifier\")\n",
    "print('Precision= {:.2f}'.format(precision_score(y_test, y_pred, average=\"weighted\")))\n",
    "print('Recall= {:.2f}'. format(recall_score(y_test, y_pred, average=\"weighted\")))\n",
    "print('F1= {:.2f}'. format(f1_score(y_test, y_pred, average=\"weighted\")))\n",
    "print('Accuracy= {:.2f}'. format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 2)\n",
    "model = GaussianNB()\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Gaussian Naie Bayes\")\n",
    "print('Precision= {:.2f}'.format(precision_score(y_test, y_pred, average=\"weighted\")))\n",
    "print('Recall= {:.2f}'. format(recall_score(y_test, y_pred, average=\"weighted\")))\n",
    "print('F1= {:.2f}'. format(f1_score(y_test, y_pred, average=\"weighted\")))\n",
    "print('Accuracy= {:.2f}'. format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Binning\n",
    "rslt_df_sl['cases_new_category'] = (pd.cut(rslt_df_sl['cases_new'].values, bins=getBinsRange(rslt_df_sl),labels=labels, include_lowest=True))\n",
    "X = rslt_df_sl.drop(['cases_new','date','state','cases_new_category'], axis=1)\n",
    "y = rslt_df_sl.cases_new_category # Target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1)\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=5, splitter='random') #pruning the tree by setting the depth\n",
    "# Train Decision Tree Classifer*\n",
    "clf = clf.fit(X_train,y_train)\n",
    "#Predict the response for test dataset*\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Decision Tree Classifier\")\n",
    "print('Precision= {:.2f}'.format(precision_score(y_test, y_pred, average=\"weighted\")))\n",
    "print('Recall= {:.2f}'. format(recall_score(y_test, y_pred, average=\"weighted\")))\n",
    "print('F1= {:.2f}'. format(f1_score(y_test, y_pred, average=\"weighted\")))\n",
    "print('Accuracy= {:.2f}'. format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 2)\n",
    "model = GaussianNB()\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Gaussian Naie Bayes\")\n",
    "print('Precision= {:.2f}'.format(precision_score(y_test, y_pred, average=\"weighted\")))\n",
    "print('Recall= {:.2f}'. format(recall_score(y_test, y_pred, average=\"weighted\")))\n",
    "print('F1= {:.2f}'. format(f1_score(y_test, y_pred, average=\"weighted\")))\n",
    "print('Accuracy= {:.2f}'. format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
